{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running Python 3. Good job :)\n"
     ]
    }
   ],
   "source": [
    "# Check the Python version\n",
    "import sys\n",
    "if sys.version.startswith(\"3.\"):\n",
    "  print(\"You are running Python 3. Good job :)\")\n",
    "else:\n",
    "  print(\"This notebook requires Python 3.\\nIf you are using Google Colab, go to Runtime > Change runtime type and choose Python 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "  # Clone the entire repo to access the files.\n",
    "  !git clone -l -s https://github.com/epfml/OptML_course.git cloned-repo\n",
    "  %cd cloned-repo/labs/ex02/template/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "b, A = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples n =  10000\n",
      "Dimension of each sample d =  2\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples n = ', b.shape[0])\n",
    "print('Dimension of each sample d = ', A.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Estimation\n",
    "Least squares estimation is one of the fundamental machine learning algorithms. Given an $ n \\times d $ matrix $A$ and a $ n \\times 1$ vector $b$, the goal is to find a vector $x \\in \\mathbb{R}^d$ which minimizes the objective function $$f(x) = \\frac{1}{2n} \\sum_{i=1}^{n} (a_i^\\top x - b_i)^2 = \\frac{1}{2n} \\|Ax - b\\|^2 $$\n",
    "\n",
    "In this exercise, we will try to fit $x$ using Least Squares Estimation. \n",
    "\n",
    "One can see the function is $L$ smooth with $L =\\frac1n\\|A^T A\\|  = \\frac1n\\|A\\|^2$ (Lemma 2.3 for the first equality, and a few manipulations for the second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Objective Function\n",
    "Fill in the `calculate_objective` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective(Axmb):\n",
    "    \"\"\"Calculate the mean squared error for vector Axmb = Ax - b.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute mean squared error\n",
    "    return np.sum(Axmb**2)\n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute smoothness constant $L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the spectral norm of A you can use np.linalg.norm(A, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_L(b, A):\n",
    "    \"\"\"Calculate the smoothness constant for f\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute ||A.T*A||\n",
    "    # ***************************************************\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute L = smoothness constant of f\n",
    "    # ***************************************************\n",
    "    n=len(b)\n",
    "    return np.linalg.norm(A,2)**2/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(b, A, x):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute gradient and objective\n",
    "    Axmb = A@x-b\n",
    "    n = len(b)\n",
    "    grad = A.T @ Axmb/n\n",
    "    # ***************************************************\n",
    "    return grad, Axmb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(b, A, initial_x, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store x and objective func. values\n",
    "    xs = [initial_x]\n",
    "    objectives = []\n",
    "    x = initial_x\n",
    "    L = calculate_L(b,A)\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and objective function\n",
    "        # ***************************************************\n",
    "        grad, Axmb = compute_gradient(b,A,x)\n",
    "        obj = calculate_objective(Axmb)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update x by a gradient descent step\n",
    "        # ***************************************************\n",
    "        x = x - gamma*grad\n",
    "        # store x and objective function value\n",
    "        xs.append(x)\n",
    "        objectives.append(obj)\n",
    "        print(\"Gradient Descent({bi}/{ti}): objective={l}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=obj))\n",
    "\n",
    "    return objectives, xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function with a naive step size through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): objective=55844734.25518335\n",
      "Gradient Descent(1/49): objective=45292701.120600075\n",
      "Gradient Descent(2/49): objective=36745554.281587616\n",
      "Gradient Descent(3/49): objective=29822365.341987535\n",
      "Gradient Descent(4/49): objective=24214582.300911464\n",
      "Gradient Descent(5/49): objective=19672278.037639838\n",
      "Gradient Descent(6/49): objective=15993011.584389824\n",
      "Gradient Descent(7/49): objective=13012805.757257303\n",
      "Gradient Descent(8/49): objective=10598839.037279971\n",
      "Gradient Descent(9/49): objective=8643525.994098332\n",
      "Gradient Descent(10/49): objective=7059722.4291212\n",
      "Gradient Descent(11/49): objective=5776841.541489724\n",
      "Gradient Descent(12/49): objective=4737708.022508227\n",
      "Gradient Descent(13/49): objective=3896009.8721332173\n",
      "Gradient Descent(14/49): objective=3214234.3703294587\n",
      "Gradient Descent(15/49): objective=2661996.2138684127\n",
      "Gradient Descent(16/49): objective=2214683.3071349664\n",
      "Gradient Descent(17/49): objective=1852359.8526808745\n",
      "Gradient Descent(18/49): objective=1558877.8545730605\n",
      "Gradient Descent(19/49): objective=1321157.4361057314\n",
      "Gradient Descent(20/49): objective=1128603.8971471947\n",
      "Gradient Descent(21/49): objective=972635.53059078\n",
      "Gradient Descent(22/49): objective=846301.1536800842\n",
      "Gradient Descent(23/49): objective=743970.3083824206\n",
      "Gradient Descent(24/49): objective=661082.3236913126\n",
      "Gradient Descent(25/49): objective=593943.0560915156\n",
      "Gradient Descent(26/49): objective=539560.2493356798\n",
      "Gradient Descent(27/49): objective=495510.1758634524\n",
      "Gradient Descent(28/49): objective=459829.61635094864\n",
      "Gradient Descent(29/49): objective=430928.36314582\n",
      "Gradient Descent(30/49): objective=407518.3480496661\n",
      "Gradient Descent(31/49): objective=388556.235821781\n",
      "Gradient Descent(32/49): objective=373196.92491719464\n",
      "Gradient Descent(33/49): objective=360755.88308447954\n",
      "Gradient Descent(34/49): objective=350678.63919997984\n",
      "Gradient Descent(35/49): objective=342516.0716535354\n",
      "Gradient Descent(36/49): objective=335904.39194091543\n",
      "Gradient Descent(37/49): objective=330548.93137369334\n",
      "Gradient Descent(38/49): objective=326211.0083142434\n",
      "Gradient Descent(39/49): objective=322697.2906360887\n",
      "Gradient Descent(40/49): objective=319851.17931678356\n",
      "Gradient Descent(41/49): objective=317545.82914814644\n",
      "Gradient Descent(42/49): objective=315678.4955115502\n",
      "Gradient Descent(43/49): objective=314165.9552659074\n",
      "Gradient Descent(44/49): objective=312940.79766693665\n",
      "Gradient Descent(45/49): objective=311948.4200117705\n",
      "Gradient Descent(46/49): objective=311144.59411108587\n",
      "Gradient Descent(47/49): objective=310493.4951315312\n",
      "Gradient Descent(48/49): objective=309966.10495809204\n",
      "Gradient Descent(49/49): objective=309538.91891760624\n",
      "Gradient Descent: execution time=0.026 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "x_initial = np.zeros(A.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_objectives_naive, gradient_xs_naive = gradient_descent(b, A, x_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8ccad387b841d7bd34a0a7f9094cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "from grid_search import *\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    # Generate grid data for visualization (parameters to be swept and best combination)\n",
    "    grid_x0, grid_x1 = generate_w(num_intervals=10)\n",
    "    grid_objectives = grid_search(b, A, grid_x0, grid_x1)\n",
    "    obj_star, x0_star, x1_star = get_best_parameters(grid_x0, grid_x1, grid_objectives)\n",
    "    \n",
    "    fig = gradient_descent_visualization(\n",
    "        gradient_objectives_naive, gradient_xs_naive, grid_objectives, grid_x0, grid_x1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gradient_xs_naive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing gradient descent with a better learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): objective=55844734.25518335\n",
      "Gradient Descent(1/49): objective=307717.757376588\n",
      "Gradient Descent(2/49): objective=307717.757376588\n",
      "Gradient Descent(3/49): objective=307717.757376588\n",
      "Gradient Descent(4/49): objective=307717.757376588\n",
      "Gradient Descent(5/49): objective=307717.757376588\n",
      "Gradient Descent(6/49): objective=307717.757376588\n",
      "Gradient Descent(7/49): objective=307717.757376588\n",
      "Gradient Descent(8/49): objective=307717.757376588\n",
      "Gradient Descent(9/49): objective=307717.757376588\n",
      "Gradient Descent(10/49): objective=307717.757376588\n",
      "Gradient Descent(11/49): objective=307717.757376588\n",
      "Gradient Descent(12/49): objective=307717.757376588\n",
      "Gradient Descent(13/49): objective=307717.757376588\n",
      "Gradient Descent(14/49): objective=307717.757376588\n",
      "Gradient Descent(15/49): objective=307717.757376588\n",
      "Gradient Descent(16/49): objective=307717.757376588\n",
      "Gradient Descent(17/49): objective=307717.757376588\n",
      "Gradient Descent(18/49): objective=307717.757376588\n",
      "Gradient Descent(19/49): objective=307717.757376588\n",
      "Gradient Descent(20/49): objective=307717.757376588\n",
      "Gradient Descent(21/49): objective=307717.757376588\n",
      "Gradient Descent(22/49): objective=307717.757376588\n",
      "Gradient Descent(23/49): objective=307717.757376588\n",
      "Gradient Descent(24/49): objective=307717.757376588\n",
      "Gradient Descent(25/49): objective=307717.757376588\n",
      "Gradient Descent(26/49): objective=307717.757376588\n",
      "Gradient Descent(27/49): objective=307717.757376588\n",
      "Gradient Descent(28/49): objective=307717.757376588\n",
      "Gradient Descent(29/49): objective=307717.757376588\n",
      "Gradient Descent(30/49): objective=307717.757376588\n",
      "Gradient Descent(31/49): objective=307717.757376588\n",
      "Gradient Descent(32/49): objective=307717.757376588\n",
      "Gradient Descent(33/49): objective=307717.757376588\n",
      "Gradient Descent(34/49): objective=307717.757376588\n",
      "Gradient Descent(35/49): objective=307717.757376588\n",
      "Gradient Descent(36/49): objective=307717.757376588\n",
      "Gradient Descent(37/49): objective=307717.757376588\n",
      "Gradient Descent(38/49): objective=307717.757376588\n",
      "Gradient Descent(39/49): objective=307717.757376588\n",
      "Gradient Descent(40/49): objective=307717.757376588\n",
      "Gradient Descent(41/49): objective=307717.757376588\n",
      "Gradient Descent(42/49): objective=307717.757376588\n",
      "Gradient Descent(43/49): objective=307717.757376588\n",
      "Gradient Descent(44/49): objective=307717.757376588\n",
      "Gradient Descent(45/49): objective=307717.757376588\n",
      "Gradient Descent(46/49): objective=307717.757376588\n",
      "Gradient Descent(47/49): objective=307717.757376588\n",
      "Gradient Descent(48/49): objective=307717.757376588\n",
      "Gradient Descent(49/49): objective=307717.757376588\n",
      "Gradient Descent: execution time=0.039 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: a better learning rate using the smoothness of f\n",
    "# ***************************************************\n",
    "gamma = 1/calculate_L(b,A)\n",
    "\n",
    "# Initialization\n",
    "x_initial = np.zeros(A.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_objectives, gradient_xs = gradient_descent(b, A, x_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time visualization with a better learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3730320fa7d64856849ee4ff3cfbb9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_figure(n_iter):\n",
    "    # Generate grid data for visualization (parameters to be swept and best combination)\n",
    "    grid_x0, grid_x1 = generate_w(num_intervals=10)\n",
    "    grid_objectives = grid_search(b, A, grid_x0, grid_x1)\n",
    "    obj_star, x0_star, x1_star = get_best_parameters(grid_x0, grid_x1, grid_objectives)\n",
    "    \n",
    "    fig = gradient_descent_visualization(\n",
    "        gradient_objectives, gradient_xs, grid_objectives, grid_x0, grid_x1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gradient_xs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading more complex data\n",
    "The data is taken from https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"Concrete_Data.csv\",delimiter=\",\")\n",
    "\n",
    "A = data[:,:-1]\n",
    "b = data[:,-1]\n",
    "A, mean_A, std_A = standardize(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples n =  1030\n",
      "Dimension of each sample d =  8\n"
     ]
    }
   ],
   "source": [
    "n=b.shape[0]\n",
    "d=A.shape[1]\n",
    "print('Number of samples n = ', n)\n",
    "print('Dimension of each sample d = ', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assuming bounded gradients\n",
    "Assume we are moving in a bounded region $\\|x\\| \\leq 25$ containing all iterates (and we assume $\\|x-x^\\star\\| \\leq 25$ as well, for simplicity). Then by $\\nabla f(x) = \\frac{1}{n}A^\\top (Ax - b)$, one can see that $f$ is Lipschitz over that bounded region, with Lipschitz constant $\\|\\nabla f(x)\\| \\leq \\frac{1}{n} (\\|A^\\top A\\|\\|x\\| + \\|A^\\top b\\|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: Compute the bound on the gradient norm\n",
    "# ***************************************************\n",
    "grad_norm_bound = np.linalg.norm(A,2)*25/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the learning rate assuming bounded gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): objective=1608589.3194\n",
      "Gradient Descent(1/49): objective=1566802.0875213996\n",
      "Gradient Descent(2/49): objective=1601221.3735112962\n",
      "Gradient Descent(3/49): objective=1771980.002484974\n",
      "Gradient Descent(4/49): objective=2750470.570112402\n",
      "Gradient Descent(5/49): objective=8879318.743683964\n",
      "Gradient Descent(6/49): objective=48074275.637819886\n",
      "Gradient Descent(7/49): objective=299792889.259684\n",
      "Gradient Descent(8/49): objective=1917738643.0706446\n",
      "Gradient Descent(9/49): objective=12318969016.241016\n",
      "Gradient Descent(10/49): objective=79187210086.00871\n",
      "Gradient Descent(11/49): objective=509077856527.06036\n",
      "Gradient Descent(12/49): objective=3272814687169.831\n",
      "Gradient Descent(13/49): objective=21040690038992.35\n",
      "Gradient Descent(14/49): objective=135269154020862.75\n",
      "Gradient Descent(15/49): objective=869636200486139.2\n",
      "Gradient Descent(16/49): objective=5590832140077820.0\n",
      "Gradient Descent(17/49): objective=3.5943080678002708e+16\n",
      "Gradient Descent(18/49): objective=2.310756282793286e+17\n",
      "Gradient Descent(19/49): objective=1.485569544497254e+18\n",
      "Gradient Descent(20/49): objective=9.550625862277091e+18\n",
      "Gradient Descent(21/49): objective=6.140032602275195e+19\n",
      "Gradient Descent(22/49): objective=3.947385323295279e+20\n",
      "Gradient Descent(23/49): objective=2.5377472563901487e+21\n",
      "Gradient Descent(24/49): objective=1.6315005021956526e+22\n",
      "Gradient Descent(25/49): objective=1.0488806093523251e+23\n",
      "Gradient Descent(26/49): objective=6.74318231097532e+23\n",
      "Gradient Descent(27/49): objective=4.3351461809488564e+24\n",
      "Gradient Descent(28/49): objective=2.7870360822970542e+25\n",
      "Gradient Descent(29/49): objective=1.7917665978971862e+26\n",
      "Gradient Descent(30/49): objective=1.1519145954845505e+27\n",
      "Gradient Descent(31/49): objective=7.405580820892586e+27\n",
      "Gradient Descent(32/49): objective=4.76099769112681e+28\n",
      "Gradient Descent(33/49): objective=3.0608131304119247e+29\n",
      "Gradient Descent(34/49): objective=1.967776005596999e+30\n",
      "Gradient Descent(35/49): objective=1.2650698501421342e+31\n",
      "Gradient Descent(36/49): objective=8.13304827981727e+31\n",
      "Gradient Descent(37/49): objective=5.2286815873769365e+32\n",
      "Gradient Descent(38/49): objective=3.3614839358593845e+33\n",
      "Gradient Descent(39/49): objective=2.1610752275143523e+34\n",
      "Gradient Descent(40/49): objective=1.3893406091147139e+35\n",
      "Gradient Descent(41/49): objective=8.93197656222002e+35\n",
      "Gradient Descent(42/49): objective=5.742307162451943e+36\n",
      "Gradient Descent(43/49): objective=3.691690335084268e+37\n",
      "Gradient Descent(44/49): objective=2.373362682384837e+38\n",
      "Gradient Descent(45/49): objective=1.525818774290114e+39\n",
      "Gradient Descent(46/49): objective=9.809385431293677e+39\n",
      "Gradient Descent(47/49): objective=6.306387374506177e+40\n",
      "Gradient Descent(48/49): objective=4.05433367828079e+41\n",
      "Gradient Descent(49/49): objective=2.6065036285737196e+42\n",
      "Gradient Descent: execution time=0.020 seconds\n"
     ]
    }
   ],
   "source": [
    "max_iters = 50\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: Compute learning rate based on bounded gradient\n",
    "# ***************************************************\n",
    "gamma = 25/(np.sqrt(max_iters)*calculate_L(b,A))\n",
    "\n",
    "# Initialization\n",
    "x_initial = np.zeros(A.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "bd_gradient_objectives, bd_gradient_xs = gradient_descent(b, A, x_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "\n",
    "# Averaging the iterates as is the case for bounded gradients case\n",
    "bd_gradient_objectives_averaged = []\n",
    "for i in range(len(bd_gradient_xs)):\n",
    "    if i > 0:\n",
    "        bd_gradient_xs[i] = (i * bd_gradient_xs[i-1] + bd_gradient_xs[i])/(i + 1)\n",
    "    grad, err = compute_gradient(b, A, bd_gradient_xs[i])\n",
    "    obj = calculate_objective(err)\n",
    "    bd_gradient_objectives_averaged.append(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent using smoothness\n",
    "Fill in the learning rate using smoothness of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): objective=1608589.3194\n",
      "Gradient Descent(1/49): objective=1486300.8274136996\n",
      "Gradient Descent(2/49): objective=1455975.7783689671\n",
      "Gradient Descent(3/49): objective=1446461.8783659479\n",
      "Gradient Descent(4/49): objective=1442658.3154793829\n",
      "Gradient Descent(5/49): objective=1440749.0202057152\n",
      "Gradient Descent(6/49): objective=1439582.618582006\n",
      "Gradient Descent(7/49): objective=1438756.0068379738\n",
      "Gradient Descent(8/49): objective=1438111.0913902302\n",
      "Gradient Descent(9/49): objective=1437579.3264737932\n",
      "Gradient Descent(10/49): objective=1437127.4665092193\n",
      "Gradient Descent(11/49): objective=1436737.1031394051\n",
      "Gradient Descent(12/49): objective=1436396.5468463483\n",
      "Gradient Descent(13/49): objective=1436097.4703507535\n",
      "Gradient Descent(14/49): objective=1435833.4530986706\n",
      "Gradient Descent(15/49): objective=1435599.3058894658\n",
      "Gradient Descent(16/49): objective=1435390.7255587308\n",
      "Gradient Descent(17/49): objective=1435204.095468116\n",
      "Gradient Descent(18/49): objective=1435036.3548347554\n",
      "Gradient Descent(19/49): objective=1434884.903859145\n",
      "Gradient Descent(20/49): objective=1434747.5298551985\n",
      "Gradient Descent(21/49): objective=1434622.3472995744\n",
      "Gradient Descent(22/49): objective=1434507.7480648316\n",
      "Gradient Descent(23/49): objective=1434402.3596163478\n",
      "Gradient Descent(24/49): objective=1434305.009686706\n",
      "Gradient Descent(25/49): objective=1434214.6963329222\n",
      "Gradient Descent(26/49): objective=1434130.5625172604\n",
      "Gradient Descent(27/49): objective=1434051.8745113662\n",
      "Gradient Descent(28/49): objective=1433978.0035412132\n",
      "Gradient Descent(29/49): objective=1433908.4101831042\n",
      "Gradient Descent(30/49): objective=1433842.6310966997\n",
      "Gradient Descent(31/49): objective=1433780.2677440844\n",
      "Gradient Descent(32/49): objective=1433720.9767969279\n",
      "Gradient Descent(33/49): objective=1433664.4619786206\n",
      "Gradient Descent(34/49): objective=1433610.4671263015\n",
      "Gradient Descent(35/49): objective=1433558.7702899529\n",
      "Gradient Descent(36/49): objective=1433509.1787131664\n",
      "Gradient Descent(37/49): objective=1433461.5245634825\n",
      "Gradient Descent(38/49): objective=1433415.661300003\n",
      "Gradient Descent(39/49): objective=1433371.4605828188\n",
      "Gradient Descent(40/49): objective=1433328.809643097\n",
      "Gradient Descent(41/49): objective=1433287.609044839\n",
      "Gradient Descent(42/49): objective=1433247.7707796632\n",
      "Gradient Descent(43/49): objective=1433209.2166447523\n",
      "Gradient Descent(44/49): objective=1433171.8768615797\n",
      "Gradient Descent(45/49): objective=1433135.6888993823\n",
      "Gradient Descent(46/49): objective=1433100.5964727467\n",
      "Gradient Descent(47/49): objective=1433066.5486872687\n",
      "Gradient Descent(48/49): objective=1433033.49931114\n",
      "Gradient Descent(49/49): objective=1433001.406153847\n",
      "Gradient Descent: execution time=0.021 seconds\n"
     ]
    }
   ],
   "source": [
    "max_iters = 50\n",
    "\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: a better learning rate using the smoothness of f\n",
    "# ***************************************************\n",
    "gamma = 1/calculate_L(b,A)\n",
    "\n",
    "# Initialization\n",
    "x_initial = np.zeros(A.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_objectives, gradient_xs = gradient_descent(b, A, x_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Evolution of the Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Objective Function')\n",
    "#plt.yscale(\"log\")\n",
    "plt.plot(range(len(gradient_objectives)), gradient_objectives,'r', label='gradient descent with 1/L stepsize')\n",
    "plt.plot(range(len(bd_gradient_objectives)), bd_gradient_objectives,'b', label='gradient descent assuming bounded gradients')\n",
    "plt.plot(range(len(bd_gradient_objectives_averaged)), bd_gradient_objectives_averaged,'g', label='gradient descent assuming bounded gradients with averaged iterates')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "state": {
    "d2b2c3aea192430e81437f33ba0b0e69": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e4a6a7a70ccd42ddb112989c04f2ed3f": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
